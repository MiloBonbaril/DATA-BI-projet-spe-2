{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a841dca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "# test pytorch device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1824e181",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/camelyon17_v1.0/metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e690c2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 455954 entries, 0 to 455953\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count   Dtype\n",
      "---  ------      --------------   -----\n",
      " 0   Unnamed: 0  455954 non-null  int64\n",
      " 1   patient     455954 non-null  int64\n",
      " 2   node        455954 non-null  int64\n",
      " 3   x_coord     455954 non-null  int64\n",
      " 4   y_coord     455954 non-null  int64\n",
      " 5   tumor       455954 non-null  int64\n",
      " 6   slide       455954 non-null  int64\n",
      " 7   center      455954 non-null  int64\n",
      " 8   split       455954 non-null  int64\n",
      "dtypes: int64(9)\n",
      "memory usage: 31.3 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1d5831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>patient</th>\n",
       "      <th>node</th>\n",
       "      <th>x_coord</th>\n",
       "      <th>y_coord</th>\n",
       "      <th>tumor</th>\n",
       "      <th>slide</th>\n",
       "      <th>center</th>\n",
       "      <th>split</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3328</td>\n",
       "      <td>21792</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>data/camelyon17_v1.0/patches/patient_004_node_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3200</td>\n",
       "      <td>22272</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>data/camelyon17_v1.0/patches/patient_004_node_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3168</td>\n",
       "      <td>22272</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>data/camelyon17_v1.0/patches/patient_004_node_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3328</td>\n",
       "      <td>21760</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>data/camelyon17_v1.0/patches/patient_004_node_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3232</td>\n",
       "      <td>22240</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>data/camelyon17_v1.0/patches/patient_004_node_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  patient  node  x_coord  y_coord  tumor  slide  center  split  \\\n",
       "0           0        4     4     3328    21792      1      0       0      0   \n",
       "1           1        4     4     3200    22272      1      0       0      0   \n",
       "2           2        4     4     3168    22272      1      0       0      0   \n",
       "3           3        4     4     3328    21760      1      0       0      0   \n",
       "4           4        4     4     3232    22240      1      0       0      0   \n",
       "\n",
       "                                            img_path  \n",
       "0  data/camelyon17_v1.0/patches/patient_004_node_...  \n",
       "1  data/camelyon17_v1.0/patches/patient_004_node_...  \n",
       "2  data/camelyon17_v1.0/patches/patient_004_node_...  \n",
       "3  data/camelyon17_v1.0/patches/patient_004_node_...  \n",
       "4  data/camelyon17_v1.0/patches/patient_004_node_...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_path(row):\n",
    "    p = f\"{row.patient:03d}\"\n",
    "    return (\n",
    "        f\"..data/camelyon17_v1.0/patches/\"\n",
    "        f\"patient_{p}_node_{row.node}/\"\n",
    "        f\"patch_patient_{p}_node_{row.node}_x_{row.x_coord}_y_{row.y_coord}.png\"\n",
    "    )\n",
    "\n",
    "df[\"img_path\"] = df.apply(make_path, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33695461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient: 43 unique values -> encoded to 0-42\n",
      "node: 5 unique values -> encoded to 0-4\n",
      "slide: 50 unique values -> encoded to 0-49\n",
      "center: 5 unique values -> encoded to 0-4\n",
      "\n",
      "Train set size: 410359\n",
      "Validation set size: 45595\n"
     ]
    }
   ],
   "source": [
    "cat_cols = [\"patient\", \"node\", \"slide\", \"center\"]\n",
    "cont_cols = [\"x_coord\", \"y_coord\"]\n",
    "\n",
    "# Create label encoders for categorical columns to map to 0-indexed consecutive integers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoders = {}\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[f\"{col}_encoded\"] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n",
    "    print(f\"{col}: {df[col].nunique()} unique values -> encoded to 0-{len(le.classes_)-1}\")\n",
    "\n",
    "# Update to use encoded columns\n",
    "cat_cols_encoded = [f\"{col}_encoded\" for col in cat_cols]\n",
    "\n",
    "# IMPORTANT: Recreate train/val splits AFTER encoding\n",
    "train_df = df[df[\"split\"] == 0].copy()\n",
    "val_df = df[df[\"split\"] == 1].copy()\n",
    "\n",
    "print(\"\\nTrain set size:\", len(train_df))\n",
    "print(\"Validation set size:\", len(val_df))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_cont = scaler.fit_transform(train_df[cont_cols])\n",
    "val_cont = scaler.transform(val_df[cont_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f24d6032",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CamelyonDataset(Dataset):\n",
    "    def __init__(self, df, cont_array, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.cont = cont_array.astype(np.float32)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = Image.open(row.img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        # Use encoded categorical columns\n",
    "        cat = torch.tensor([int(row[col]) for col in cat_cols_encoded], dtype=torch.long)\n",
    "        cont = torch.tensor(self.cont[idx], dtype=torch.float32)\n",
    "        y = torch.tensor(row.tumor, dtype=torch.float32)\n",
    "        return img, cat, cont, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "155df2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_ds = CamelyonDataset(train_df, train_cont, transform=transform)\n",
    "val_ds = CamelyonDataset(val_df, val_cont, transform=transform)\n",
    "\n",
    "# On Windows, num_workers must be 0 to avoid multiprocessing issues in notebooks\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_ds, batch_size=64, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "951e6893",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiModalModel(nn.Module):\n",
    "    def __init__(self, cat_sizes, cont_dim, emb_dim=8, hidden=128):\n",
    "        super().__init__()\n",
    "        # CNN\n",
    "        self.cnn = models.resnet18(weights=None)\n",
    "        self.cnn.fc = nn.Identity()\n",
    "        cnn_out = 512\n",
    "\n",
    "        # Embeddings categoriels\n",
    "        self.embeddings = nn.ModuleList([\n",
    "            nn.Embedding(size, emb_dim) for size in cat_sizes\n",
    "        ])\n",
    "        emb_out = emb_dim * len(cat_sizes)\n",
    "\n",
    "        # MLP meta\n",
    "        self.meta_mlp = nn.Sequential(\n",
    "            nn.Linear(emb_out + cont_dim, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "\n",
    "        # Tete finale\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(cnn_out + hidden, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, img, cat, cont):\n",
    "        img_feat = self.cnn(img)\n",
    "        emb_list = [emb(cat[:, i]) for i, emb in enumerate(self.embeddings)]\n",
    "        meta = torch.cat(emb_list + [cont], dim=1)\n",
    "        meta_feat = self.meta_mlp(meta)\n",
    "        fused = torch.cat([img_feat, meta_feat], dim=1)\n",
    "        logits = self.classifier(fused).squeeze(1)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "858d985d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding sizes:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [43, 5, 50, 5]\n"
     ]
    }
   ],
   "source": [
    "cat_sizes = [df[c].nunique() for c in cat_cols_encoded]\n",
    "print(\"Embedding sizes:\", cat_sizes)\n",
    "\n",
    "model = MultiModalModel(cat_sizes, cont_dim=len(cont_cols)).to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0ea1d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 6412/6412 [1:03:17<00:00,  1.69it/s, loss=0.0926, acc=0.9660]\n",
      "Val: 100%|██████████| 713/713 [07:10<00:00,  1.66it/s, loss=0.0718, acc=0.9740]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Summary | Train Loss: 0.0926 Acc: 0.9660 | Val Loss: 0.0718 Acc: 0.9740\n",
      "\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 6412/6412 [56:38<00:00,  1.89it/s, loss=0.0499, acc=0.9824]\n",
      "Val: 100%|██████████| 713/713 [07:27<00:00,  1.59it/s, loss=0.0397, acc=0.9861]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Summary | Train Loss: 0.0499 Acc: 0.9824 | Val Loss: 0.0397 Acc: 0.9861\n",
      "\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 6412/6412 [1:04:30<00:00,  1.66it/s, loss=0.0384, acc=0.9865]\n",
      "Val: 100%|██████████| 713/713 [07:12<00:00,  1.65it/s, loss=0.0382, acc=0.9862]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Summary | Train Loss: 0.0384 Acc: 0.9865 | Val Loss: 0.0382 Acc: 0.9862\n",
      "\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 6412/6412 [1:00:55<00:00,  1.75it/s, loss=0.0314, acc=0.9891]\n",
      "Val: 100%|██████████| 713/713 [06:48<00:00,  1.74it/s, loss=0.0586, acc=0.9784]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Summary | Train Loss: 0.0314 Acc: 0.9891 | Val Loss: 0.0586 Acc: 0.9784\n",
      "\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 6412/6412 [1:01:52<00:00,  1.73it/s, loss=0.0254, acc=0.9910]\n",
      "Val: 100%|██████████| 713/713 [07:49<00:00,  1.52it/s, loss=0.0324, acc=0.9882]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Summary | Train Loss: 0.0254 Acc: 0.9910 | Val Loss: 0.0324 Acc: 0.9882\n",
      "\n",
      "Training completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def run_epoch(loader, train=True):\n",
    "    model.train() if train else model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    mode = \"Train\" if train else \"Val\"\n",
    "    pbar = tqdm(loader, desc=f\"{mode}\", leave=True)\n",
    "\n",
    "    for imgs, cats, conts, y in pbar:\n",
    "        imgs, cats, conts, y = imgs.to(device), cats.to(device), conts.to(device), y.to(device)\n",
    "        logits = model(imgs, cats, conts)\n",
    "        loss = criterion(logits, y)\n",
    "\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * y.size(0)\n",
    "        preds = (torch.sigmoid(logits) > 0.5).float()\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "        # Update progress bar with current metrics\n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{total_loss/total:.4f}',\n",
    "            'acc': f'{correct/total:.4f}'\n",
    "        })\n",
    "\n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "print(\"Starting training...\")\n",
    "for epoch in range(5):\n",
    "    print(f\"\\nEpoch {epoch+1}/5\")\n",
    "    tr_loss, tr_acc = run_epoch(train_loader, train=True)\n",
    "    va_loss, va_acc = run_epoch(val_loader, train=False)\n",
    "    print(f\"Epoch {epoch+1} Summary | Train Loss: {tr_loss:.4f} Acc: {tr_acc:.4f} | Val Loss: {va_loss:.4f} Acc: {va_acc:.4f}\")\n",
    "\n",
    "print(\"\\nTraining completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e31840d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE THE MODEL\n",
    "torch.save(model.state_dict(), \"multimodal_camelyon_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
